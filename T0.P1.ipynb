{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Después de mucho investigar y estudiar el algoritmo de backpropagation e intentar implementarlo me fue imposible llegar a una solución satisfactoria, obteniendo matrices con valores NaN. Por lo cual me base en el código que se muestra en este enlace, modificandolo de manera tal que se adapte a lo pedido en el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "X_train,y_train = load_iris(return_X_y=True)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "#transform target to one hot vector\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = X_train\n",
    "training_labels = y_onehot\n",
    "\n",
    "hidden_nodes = 32\n",
    "num_labels = training_labels.shape[1]\n",
    "num_features = training_data.shape[1]\n",
    "learning_rate = .01\n",
    "reg_lambda = .01\n",
    "\n",
    "# Weights and Bias Arrays, just like in Tensorflow\n",
    "layer1_weights_array = np.random.normal(0, 1, [num_features, hidden_nodes]) \n",
    "layer2_weights_array = np.random.normal(0, 1, [hidden_nodes, 16])\n",
    "layer3_weights_array = np.random.normal(0, 1, [16, num_labels])\n",
    "\n",
    "layer1_biases_array = np.zeros((1, hidden_nodes))\n",
    "layer2_biases_array = np.zeros((1, 16))\n",
    "layer3_biases_array = np.zeros((1, num_labels))\n",
    "\n",
    "def relu_activation(data_array):\n",
    "    return np.maximum(data_array, 0)\n",
    "def softmax(output_array):\n",
    "    logits_exp = np.exp(output_array)\n",
    "    return logits_exp / np.sum(logits_exp, axis = 1, keepdims = True)\n",
    "def cross_entropy_softmax_loss_array(softmax_probs_array, y_onehot):\n",
    "    indices = np.argmax(y_onehot, axis = 1).astype(int)\n",
    "    predicted_probability = softmax_probs_array[np.arange(len(softmax_probs_array)), indices]\n",
    "    log_preds = np.log(predicted_probability)\n",
    "    loss = -1.0 * np.sum(log_preds) / len(log_preds)\n",
    "    return loss\n",
    "def regularization_L2_softmax_loss(reg_lambda, weight1, weight2, weight3):\n",
    "    weight1_loss = 0.5 * reg_lambda * np.sum(weight1 * weight1)\n",
    "    weight2_loss = 0.5 * reg_lambda * np.sum(weight2 * weight2)\n",
    "    weight3_loss = 0.5 * reg_lambda * np.sum(weight3 * weight3)\n",
    "    return weight1_loss + weight2_loss + weight3_loss\n",
    "\n",
    "loss_list = list()\n",
    "step_list = list()\n",
    "\n",
    "for step in range(5001):\n",
    "\n",
    "    input_layer = np.dot(training_data, layer1_weights_array)\n",
    "    hidden_layer1 = relu_activation(input_layer + layer1_biases_array)\n",
    "    hidden_layer2 = relu_activation(np.dot(hidden_layer1, layer2_weights_array) + layer2_biases_array)\n",
    "    output_layer = np.dot(hidden_layer2, layer3_weights_array) + layer3_biases_array\n",
    "    output_probs = softmax(output_layer)\n",
    "    \n",
    "    loss = cross_entropy_softmax_loss_array(output_probs, training_labels)\n",
    "    loss += regularization_L2_softmax_loss(reg_lambda, layer1_weights_array, layer2_weights_array, layer3_weights_array)\n",
    "\n",
    "    output_error_signal = (output_probs - training_labels) / output_probs.shape[0]\n",
    "    \n",
    "    error_signal_hidden2 = np.dot(output_error_signal, layer3_weights_array.T) \n",
    "    error_signal_hidden2[hidden_layer2 <= 0] = 0\n",
    "    \n",
    "    error_signal_hidden1 = np.dot(error_signal_hidden2, layer2_weights_array.T) \n",
    "    error_signal_hidden1[hidden_layer1 <= 0] = 0\n",
    "    \n",
    "    gradient_layer3_weights = np.dot(hidden_layer2.T, output_error_signal)\n",
    "    gradient_layer3_bias = np.sum(output_error_signal, axis = 0, keepdims = True)\n",
    "    \n",
    "    gradient_layer2_weights = np.dot(hidden_layer1.T, error_signal_hidden2)\n",
    "    gradient_layer2_bias = np.sum(error_signal_hidden2, axis = 0, keepdims = True)\n",
    "    \n",
    "    gradient_layer1_weights = np.dot(training_data.T, error_signal_hidden1)\n",
    "    gradient_layer1_bias = np.sum(error_signal_hidden1, axis = 0, keepdims = True)\n",
    "\n",
    "    gradient_layer3_weights += reg_lambda * layer3_weights_array\n",
    "    gradient_layer2_weights += reg_lambda * layer2_weights_array\n",
    "    gradient_layer1_weights += reg_lambda * layer1_weights_array\n",
    "\n",
    "    layer1_weights_array -= learning_rate * gradient_layer1_weights\n",
    "    layer1_biases_array -= learning_rate * gradient_layer1_bias\n",
    "    layer2_weights_array -= learning_rate * gradient_layer2_weights\n",
    "    layer2_biases_array -= learning_rate * gradient_layer2_bias\n",
    "    layer3_weights_array -= learning_rate * gradient_layer3_weights\n",
    "    layer3_biases_array -= learning_rate * gradient_layer3_bias\n",
    "   \n",
    "    if step % 500 == 0:\n",
    "            loss_list.append(loss)\n",
    "            step_list.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAADgCAYAAAA9kMHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmUnNV95vHnqepNOwIJoRVJjbyADbJpy4ABCW+Dl8GO\nlxjGGwasSHESZ5JJ4mTmzEycmTNJ5ozjONiSARvwBsGxsbGDF4wtIdtgaGEWsRltCAmBJITQ0uru\nWn7zR70tVbe6pZa6q97uqu/nnDp13/tuv+ba8NTt2285IgQAAABgeGXSLgAAAACoRQRtAAAAoAII\n2gAAAEAFELQBAACACiBoAwAAABVA0AYAAAAqgKANADXIdtg+o4r3m5vcs6Fa9wSAkY6gDQAVZnuz\n7YO295e9rk27LgBAZTHzAADV8R8j4mdpFwEAqB5mtAEgRbavtP0r29faftn2k7bfUrZ/hu07bO+2\nvd72J8v2ZW3/je0NtvfZXmt7dtnl32r7adt7bH/Rtvu5/4xktv3ksr7X2d5lu9H2GbZXJ7Xtsv2v\ng/y5jlb3ItvttvfafsH255L+FtvfsP1iUvMDtqcd5z9SABgxmNEGgPS9UdK/SZoi6X2Svmt7XkTs\nlnSrpHWSZkh6laS7bG+IiJ9L+jNJV0h6p6TfSTpbUkfZdd8t6Q2SJkpaK+kHkn5cfuOIeM72vZLe\nL+n6pPs/Sfq3iMjZ/jtJP5V0iaQmSW2D/JmOVvc/S/rniPi67fGSXpOc83FJkyTNltQlaaGkg4O8\nHwCMOMxoA0B1fC+Zpe15fbJs3w5Jn4+IXET8q6SnJL0rmZ1+k6S/iojOiHhI0g2SPpacd42k/xYR\nT0XJwxHxYtl1/z4i9kTEFkm/UCm49udbKgV2JbPelyd9kpSTdLqkGUkNvzzWDzqIunOSzrA9JSL2\nR8R9Zf2nSDojIgoRsTYi9h7rfgAwUhG0AaA63hsRJ5W9ri/bty0iomz7GZVmgmdI2h0R+/rsm5m0\nZ0vacJR7Pl/W7pA0foDjviPpfNvTJV0sqShpTbLvLyVZ0v22H7N91VHu1+NYdV8t6RWSnkyWh7w7\n6f+6pJ9IutX2c7b/0XbjIO4HACMSQRsA0jezz/rpOZKeS14n257QZ9+2pP2spNah3jwiXlJpeciH\nVFo2cmtP8I+I5yPikxExQ9IfSPrSIB4beNS6I+LpiLhC0qmS/kHSv9kel8zo/21EnCnpApWWvnxM\nADBKEbQBIH2nSvqT5I8PPyjp1ZLujIhnJf1a0v9J/lDwbJVmg7+RnHeDpL+zvcAlZ9s+5QRr+JZK\nofYDOrxsRLY/aHtWsvmSpFBpxntAx6rb9kdsT42IoqQ9yWlF25fYfq3trKS9Ki0lOeq9AGAk448h\nAaA6fmC7ULZ9V0T8XtL+jaQFknZJekHSB8rWWl8haaVKs8QvSfofZY8J/JykZpVmo6dIelJSzzWP\n1x0qBfctEfFwWf8bJH3e9qSktk9HxMZBXO9odV8q6XO2x6q0pOTyiDho+7TknFmS9kv6V5WWkwDA\nqOTeywIBANVk+0pJ10TEhWnXAgAYXiwdAQAAACqAoA0AAABUAEtHAAAAgApgRhsAAACoAII2AAAA\nUAE19Xi/KVOmxNy5c9MuAwAAADVs7dq1uyJi6rGOq6mgPXfuXLW3t6ddBgAAAGqY7WcGcxxLRwAA\nAIAKIGgDAAAAFUDQBgAAACqAoA0AAABUAEF7iG5Ys1ErVm1IuwwAAACMMATtIXp028u69udP6+WO\nXNqlAAAAYAQhaA/RssWtOtBd0Dd+M6invAAAAKBOELSH6NXTJ+qSV07VV3+5SZ25QtrlAAAAYIQg\naA+DZYtb9eKBbn27/dm0SwEAAMAIQdAeBovmnazXzzlJX75no/KFYtrlAAAAYAQgaA8D21q+5Axt\nfemg/v3R7WmXAwAAgBGAoD1M3vKqU7Xg1PFasWqDIiLtcgAAAJAygvYwyWSsZYtb9eTz+7TqqZ1p\nlwMAAICUVSxo2/6q7R2215X1/U/b22w/lLzeOcC5l9p+yvZ625+pVI3D7bKFMzRjUgtfYAMAAICK\nzmjfJOnSfvr/KSIWJq87++60nZX0RUnvkHSmpCtsn1nBOodNYzajT148X/dv3q32zbvTLgcAAAAp\nqljQjoh7JJ1I2lwkaX1EbIyIbkm3SnrPsBZXQR96w2xNHtuolauZ1QYAAKhnaazR/mPbjyRLSyb3\ns3+mpPIHUm9N+vple6ntdtvtO3emvzZ6bFODrrxgnn72xA499fy+tMsBAABASqodtFdImi9poaTt\nkv7fUC8YEddFRFtEtE2dOnWolxsWHzv/dI1tyurLzGoDAADUraoG7Yh4ISIKEVGUdL1Ky0T62iZp\ndtn2rKRv1Jg8rklXLJqj7z/8nLa+1JF2OQAAAEhBVYO27ellm78naV0/hz0gaYHtebabJF0u6Y5q\n1DecrrlonjKWblizKe1SAAAAkIJKPt7vFkn3Snql7a22r5b0j7Yftf2IpEsk/efk2Bm275SkiMhL\n+iNJP5H0hKTbIuKxStVZKdMnjdF7F87UrQ9s0e4D3WmXAwAAgCpzLX2LYVtbW7S3t6ddxiHrd+zT\n2/7pHv3xmxfoz972irTLAQAAwDCwvTYi2o51HN8MWUFnnDpBbz9zmm7+9WYd6MqnXQ4AAACqiKBd\nYcsWt+rlgzndcv+WtEsBAABAFRG0K+x1cybr/Pmn6IY1m9SdL6ZdDgAAAKqEoF0Fy5e06vm9nfre\nQ6PqKYUAAAAYAoJ2FVy0YIrOmjFRK1dvULFYO398CgAAgIERtKvAtpYvadXGnQf008dfSLscAAAA\nVAFBu0re8ZrpOv2UsVqxeoNq6ZGKAAAA6B9Bu0qyGWvpxfP18LN7dO/GF9MuBwAAABVG0K6i979+\nlqaMb9aKVRvSLgUAAAAVRtCuopbGrK6+cJ7WPL1L67a9nHY5AAAAqCCCdpV9+Lw5mtDcoBWrmdUG\nAACoZQTtKpvY0qiPnH+6fvTodm3adSDtcgAAAFAhBO0UfOJNc9WQzei6ezamXQoAAAAqhKCdglMn\ntOiD587Sd9Zu1Y69nWmXAwAAgAogaKdk6cXzlS8W9ZVfbUq7FAAAAFQAQTslp58yTu86e4a+ed8W\nvXwwl3Y5AAAAGGYVC9q2v2p7h+11ZX3/1/aTth+xfbvtkwY4d7PtR20/ZLu9UjWmbdni+drfldc3\n7nsm7VIAAAAwzCo5o32TpEv79N0l6TURcbak30n666Ocf0lELIyItgrVl7qzZkzS4ldM1Y2/2qTO\nXCHtcgAAADCMKha0I+IeSbv79P00IvLJ5n2SZlXq/qPF8iWt2rW/W99euzXtUgAAADCM0lyjfZWk\nHw2wLyT9zPZa20uPdhHbS223227fuXPnsBdZaW+cd7JeN+ckXXfPBuULxbTLAQAAwDBJJWjb/q+S\n8pK+OcAhF0bEQknvkPQp2xcPdK2IuC4i2iKiberUqRWotrJsa/niVj27+6DuXPd82uUAAABgmFQ9\naNu+UtK7JX04IqK/YyJiW/K+Q9LtkhZVrcAUvPXV03TGqeO1YtUGDfCPBAAAAKNMVYO27Usl/aWk\nyyKiY4Bjxtme0NOW9HZJ6/o7tlZkMtayxa16Yvterf7d6Fv+AgAAgCNV8vF+t0i6V9IrbW+1fbWk\nayVNkHRX8ui+lcmxM2zfmZw6TdIvbT8s6X5J/x4RP65UnSPFZefM0IxJLVqxakPapQAAAGAYNFTq\nwhFxRT/dXxng2OckvTNpb5R0TqXqGqmaGjK65qL5+uwPH9faZ17SuadPTrskAAAADAHfDDmCXL5o\ntk4a26iVq5nVBgAAGO0I2iPI2KYGXXnBXN31+At6+oV9aZcDAACAISBojzAfP3+uxjRmtXL1xrRL\nAQAAwBAQtEeYyeOadPmi2fr+Q9u0bc/BtMsBAADACSJoj0DXXDRfknTDGma1AQAARiuC9gg086Qx\nes/Cmbr1/me1+0B32uUAAADgBBC0R6hli+frYK6gm3+9Oe1SAAAAcAII2iPUgmkT9LYzp+nmezfr\nQFc+7XIAAABwnAjaI9jyJa3a05HTrQ88m3YpAAAAOE4E7RHs9XMm643zTtYNazaqO19MuxwAAAAc\nB4L2CLd8Sau2v9yp7z+0Le1SAAAAcBwI2iPc4ldM1aunT9TK1RtULEba5QAAAGCQCNojnG0tX9Kq\nDTsP6K4nXki7HAAAAAwSQXsUeOdrTtOck8fqS6s2KIJZbQAAgNGAoD0KNGQzWnrxfD387B7dt3F3\n2uUAAABgEAjao8QHzp2lKeObtWL1hrRLAQAAwCBULGjb/qrtHbbXlfWdbPsu208n75MHOPdS20/Z\nXm/7M5WqcTRpaczqqgvn6p7f7dS6bS+nXQ4AAACOoZIz2jdJurRP32ck3R0RCyTdnWz3Yjsr6YuS\n3iHpTElX2D6zgnWOGh8573RNaG7QSma1AQAARryKBe2IuEdS3wXF75F0c9K+WdJ7+zl1kaT1EbEx\nIrol3ZqcV/cmtjTqw+edrjsf3a5nXjyQdjkAAAA4imqv0Z4WEduT9vOSpvVzzExJ5d85vjXpg6Sr\n3jRXDdmMrrtnY9qlAAAA4ChS+2PIKD2nbsjPqrO91Ha77fadO3cOQ2Uj26kTW/SBc2fp22u3ase+\nzrTLAQAAwACqHbRfsD1dkpL3Hf0cs03S7LLtWUlfvyLiuohoi4i2qVOnDmuxI9XSi+YrXyjqxl9t\nTrsUAAAADKDaQfsOSR9P2h+X9P1+jnlA0gLb82w3Sbo8OQ+JuVPG6Z2vna5v3PuM9nbm0i4HAAAA\n/ajk4/1ukXSvpFfa3mr7akl/L+lttp+W9NZkW7Zn2L5TkiIiL+mPJP1E0hOSbouIxypV52i1bHGr\n9nXl9c37tqRdCgAAAPrhwXylt+1WSVsjosv2EklnS/paROypcH3Hpa2tLdrb29Muo2o++pXf6Int\n+/TLv7pELY3ZtMsBAACoC7bXRkTbsY4b7Iz2dyQVbJ8h6TqV1lB/awj1YRgsX9KqXfu79J0Ht6Zd\nCgAAAPoYbNAuJks6fk/Sv0TEX0iaXrmyMBjnzz9F58w+SV9evVH5QjHtcgAAAFBmsEE7Z/sKlf6A\n8YdJX2NlSsJg2dbyxa3asrtDP1r3fNrlAAAAoMxgg/YnJJ0v6X9HxCbb8yR9vXJlYbDefuY0zZ86\nTitWbdBg1tsDAACgOgYVtCPi8Yj4k4i4xfZkSRMi4h8qXBsGIZOxli1u1ePb9+qep3elXQ4AAAAS\ngwratlfZnmj7ZEkPSrre9ucqWxoG670LZ+q0iS1asWp92qUAAAAgMdilI5MiYq+k96n0WL83qvQc\nbIwATQ0ZXXPRPN23cbce3PJS2uUAAABAgw/aDclXpv++Dv8xJEaQKxbN0aQxjVq5akPapQAAAECD\nD9qfVembGjdExAO250t6unJl4XiNa27Qxy+Yq58+/oLW79iXdjkAAAB1b7B/DPntiDg7IpYn2xsj\n4v2VLQ3H68oL5qqlMaOVqzemXQoAAEDdG+wfQ86yfbvtHcnrO7ZnVbo4HJ+TxzXp8jfM0fd+u03P\n7TmYdjkAAAB1bbBLR26UdIekGcnrB0kfRphrLponSbphzaaUKwEAAKhvgw3aUyPixojIJ6+bJE2t\nYF04QbMmj9VlC2folvu36KUD3WmXAwAAULcGG7RftP0R29nk9RFJL1ayMJy4ZYtbdTBX0M33bk67\nFAAAgLo12KB9lUqP9nte0nZJH5B0ZYVqwhC9YtoEvfXV03TTrzerozufdjkAAAB1abBPHXkmIi6L\niKkRcWpEvFcSTx0ZwZYvadWejpxuvf/ZtEsBAACoS4Od0e7Pn53ISbZfafuhstde23/a55gltl8u\nO+a/D6HOunTu6ZO1aN7JumHNRuUKxbTLAQAAqDtDCdo+kZMi4qmIWBgRCyWdK6lD0u39HLqm57iI\n+OwQ6qxby5e06rmXO3XHQ8+lXQoAAEDdGUrQjmG4/1tU+rbJZ4bhWuhjySum6lWnTdDK1RtULA7H\ncAEAAGCwjhq0be9Llnb0fe1T6XnaQ3W5pFsG2HeB7Uds/8j2WcNwr7pjW8uXtOrpHft195M70i4H\nAACgrhw1aEfEhIiY2M9rQkQ0DOXGtpskXSbp2/3sflDSnIg4W9K/SPreUa6z1Ha77fadO3cOpaSa\n9K7XTtesyWP0pVXrFcGsNgAAQLUMZenIUL1D0oMR8ULfHRGxNyL2J+07JTXantLfRSLiuohoi4i2\nqVP5Dp2+GrIZ/cHF8/XbLXt0/6bdaZcDAABQN9IM2ldogGUjtk+z7aS9SKU6+YKcE/TBttk6ZVyT\nVqzekHYpAAAAdSOVoG17nKS3SfpuWd8y28uSzQ9IWmf7YUlfkHR5sO7hhLU0ZnXVhfO06qmdevy5\nvWmXAwAAUBdSCdoRcSAiTomIl8v6VkbEyqR9bUScFRHnRMR5EfHrNOqsJR8573SNb27QSma1AQAA\nqiLNpSOookljGvXhN87RDx95Tlte7Ei7HAAAgJpH0K4jV104Tw2ZjK5bw6w2AABApRG068i0iS16\n/7kzdVv7Vu3c15V2OQAAADWNoF1nll7cqlyhqBt/tSntUgAAAGoaQbvOzJsyTu98zXR9/d5ntLcz\nl3Y5AAAANYugXYeWLW7Vvq68vvWbLWmXAgAAULMI2nXotbMm6aIFU/SVX25SZ66QdjkAAAA1iaBd\np5YvbtXOfV367oPb0i4FAACgJhG069T5rafonFmT9OV7NqhQ5Es3AQAAhhtBu07Z1vIlrXrmxQ79\naN32tMsBAACoOQTtOvb2M0/T/KnjtGLVBkUwqw0AADCcCNp1LJOxll3cqsee26s1T+9KuxwAAICa\nQtCuc+953QydNrFFK1bxtewAAADDiaBd55obsrrmonm6d+OL+u2Wl9IuBwAAoGYQtKHLF83RpDGN\nWrmaWW0AAIDhQtCGxjc36GPnn66fPv6C1u/Yn3Y5AAAANSGVoG17s+1HbT9ku72f/bb9BdvrbT9i\n+/Vp1FlPrrxgrpobMrruHma1AQAAhkOaM9qXRMTCiGjrZ987JC1IXkslrahqZXXolPHN+lDbbN3+\n223a/vLBtMsBAAAY9Ubq0pH3SPpalNwn6STb09MuqtZdc9F8FUP6yppNaZcCAAAw6qUVtEPSz2yv\ntb20n/0zJT1btr016UMFzT55rC47Z4a+df8W7enoTrscAACAUS2toH1hRCxUaYnIp2xffKIXsr3U\ndrvt9p07dw5fhXXqDxbPV0d3QV+795m0SwEAABjVUgnaEbEted8h6XZJi/ocsk3S7LLtWUlff9e6\nLiLaIqJt6tSplSi3rrzqtIl6y6tO1Y2/2qSO7nza5QAAAIxaVQ/atsfZntDTlvR2Sev6HHaHpI8l\nTx85T9LLEbG9yqXWreVLWvVSR063PfDssQ8GAABAv9KY0Z4m6Ze2H5Z0v6R/j4gf215me1lyzJ2S\nNkpaL+l6SX+YQp11q23uyXrD3Mm6fs0m5QrFtMsBAAAYlRqqfcOI2CjpnH76V5a1Q9KnqlkXelu+\npFVX3dSuHzz8nN73+llplwMAADDqjNTH+yFll7zyVL1y2gStXL1BxWKkXQ4AAMCoQ9BGv2xr+ZJW\n/e6F/fr5kzvSLgcAAGDUIWhjQO8+e7pmTR6jL61ar9JqHgAAAAwWQRsDashmtPTi+Xpwyx49sPml\ntMsBAAAYVQjaOKoPnjtbp4xr0opV69MuBQAAYFQhaOOoxjRl9Yk3zdUvntqpJ7bvTbscAACAUYOg\njWP66HlzNa4pq5WrN6RdCgAAwKhB0MYxTRrbqA+fd7p+8PBz2vJiR9rlAAAAjAoEbQzK1RfOU0Mm\no+vXbEy7FAAAgFGBoI1BmTaxRe97/Uzd1v6sdu7rSrscAACAEY+gjUFbevF8dReKuunXm9IuBQAA\nYMQjaGPQ5k8dr0vPOk1fu/cZ7evMpV0OAADAiNaQdgEYXZYtbtWP1j2vK298QKefMlYTmhs0rrlB\n41saNL65QeOaDrfHJ/smtJTexzZmlck47R8BAACgKgjaOC7nzD5Jf7ikVXc/sUO/2bhbB7rz2t+Z\nV7547K9ot6VxTQ0a15w9FMTHtyThvKfdfDik9wT18YeCfFbjmxs1rjmrcU0NhHYAADCiOeLYAWm0\naGtri/b29rTLqDsRoa58Ufu78jrQlde+ztL7/uR1oKug/V057e8qaH+ffT3nHNoeZGiXpHFN2V6z\n6b2CeflselNW41saNb452zvIJ8F+XFODsoR2AAAwSLbXRkTbsY5jRhtDZlstjVm1NGY1ZXzzkK7V\nE9qPFdT3JQG9vL2/M6/dBzp6hfdcYXChfWwS2ieUhfXSe7ZXIB/blNXY5H1MU2lmfUxTNukv28cy\nGQAA6l7Vg7bt2ZK+JmmapJB0XUT8c59jlkj6vqSex1t8NyI+W806kY7y0H7KEEO7JHXlC6Wg3tl7\nBr1XUB9gln3rSx060J0/dH53oXhc9x7TmD0UyMtDeN+wfvR9pRn5MWX9zQ0Z2YR4AABGujRmtPOS\n/jwiHrQ9QdJa23dFxON9jlsTEe9OoT7UkOaGrJobsjp5XNOQr5UrFNXRXdDB7oIOdOd1sLugju6C\nOrrzyXtBB5P2gbJ2z/E97Zc6ckfsG+RqGUlSxtLYZCa9FMLLQ3q2333l7Z6Z+P5m5RuzPIgIAIDh\nUvWgHRHbJW1P2vtsPyFppqS+QRsYURqzGU0ak9GkMY3Det2e5TIHuwvqyBXU0VUW3HOlGfWDSaA/\n0F04FPB79vW093fltWNvlzpypQ8BB7oKOpgrHOfP6CNm28ckv2EY01jqO7SdtMc0ZtVS1h7TlDni\n+PJjCPMAgHqR6hpt23MlvU7Sb/rZfYHtRyRtk/RfIuKxKpYGVE35cpnJw3ztYjHUmU9m3rsK6siV\nzaR35XUwVzgU6ju68urIHd7XkSuos7sU1vd35bVzX5c6c6Xtg90FdeaKx72cRpIaMj4inJfamdJs\n/KEgnxkgyB87+Dc3ZFgjDwBIXWpB2/Z4Sd+R9KcRsbfP7gclzYmI/bbfKel7khYMcJ2lkpZK0pw5\ncypYMTD6ZDI9M9QN0vjhv36+UFRnMhtfHsIPJu3OsnbvY4ql/bnSTP3BXFGd3QXt3Nd15LG5gk7k\n4UgtjYMI6kcE99JsfEtDVs2NmUMfgFoaytqNvY9hzTwAYCCpPN7PdqOkH0r6SUR8bhDHb5bUFhG7\njnYcj/cDak/P0pq+Qb6zLLAfPdQXykJ9//tPdHZeKj0fvrnhcPjuCeLNvQL6APsbM0lf2TFJX3Ov\nvt5hn8dRAkC6Ruzj/Vya+vmKpCcGCtm2T5P0QkSE7UUqfVX8i1UsE8AIUb605qQK3qdndr4zCeWd\nuVK7K3+4fei9rK8rV+j3vJ6+PR3dpb583+ueWLCXSmvpjwzjvUN7c59g3+/+JMA3J8ttWpL35rK+\n0iurxqyZuQeA45TG0pE3SfqopEdtP5T0/Y2kOZIUESslfUDSctt5SQclXR619M06AEachmxG47MZ\njW+uzr8Wi8VQd2HgAN/T39UnoPcN7V19zuvozmv3gdIxXeXXyhdVOJ7H2/SRcfIUn8bD4bsUyMva\nvcJ6/8f22n/E+cmSnT7nNjVkmMUHMCql8dSRX0o66r8xI+JaSddWpyIAqL5MxmrJlGaVqyXXJ9j3\nzNZ3JaG8K5+088VSSD/Un/TlS8H+ULvP+fs6873OL98/hIwvqTSL3zfQN/Uz894T0I8e6DOlc5Pt\nprK+prJw35QtndeUZS0+gBPDN0MCQJ1ozGbUmM1oQkt17xsRyhej36DeVbaUprzv+EJ/Qfs689qV\n7+73/O4hLNMp15TtL5RnDofyJKD3De29wnyva/Q+vvy9v7Dfcz2W8QCjB0EbAFBRttWYtRqruDSn\nXM8ynSOCer6g7iSI9wTy7sKR/V3l+8vPS67ZXTjc39GRP3Ts4fMKyXWLJ/QEnf4MLpT3BP5S2G9M\nZuYbs06Oz6qxwYdm7Buzhz8gHGqXvTeWXbf3saVrEP6BIxG0AQA1rfcyneH9wqnj0TOz391PcO/q\nG/ZzhbIAf2TI7yoL+YfDfqHXsfs6832uF+rOF5QrlD54DGXNfn96AndTnyDeX1jvCf1N/QT/5n6u\n0Vj+YaDP/v6Cf3NyrcZsRg0ZfgOA9BC0AQCogvKZ/XHNaVcjFYqhXDLTniscDug9fd2FonI972Wh\nP1eIQ8f1BPny9yP6e/qS7Y6Dhd7HlbW7CsO31KdcKeRbjWVhvWcsGrMZNTZk1FS+nc2oqcFqyBxu\n99rXc2xDn+0TulaGDwU1jKANAEAdymasbJX/IHcwemb+y4P44RAfyXZB3fk4ZrgvBfzStfKF4qHZ\n/Nyh/XHog0SuUFQuH+rozh3eLvtQUX58JT4M9BjMh4LGjPsN9Q3JbxUayvt6js1aDYcCfk/w96Hz\nGsvu0/++/q7FB4RjIWgDAIARo3zmf2xT2tX0LyKS3wgcGdR7tvN99xWK6s5H7+1ClIX+wx8Kcvk+\n2wOc33GwoFy+qHzx8AeRXKF46INKTx35YV4m1J+e8F4e9hsypeU8DZlSMG9KAnpDxn36e4f9ntn/\nUqA/+oeGs2ZM1KunT6z4z3eiCNoAAADHwS4FwIasNEYj6zcC/YkofSjIF0sfBnLFUgA/FMaTvx3I\nF0P5ZJlPPjm+O1967/ng0Pe8XL6oXHJez6x///fp+RBQau/vyh9xrcP3KLtfMY769wR//rZXELQB\nAACQDttqarCalJFG6G8JjqZYPDK094T5iWNGdpQd2dUBAACgrmUyVnMmqxSeDjpkmbQLAAAAAGoR\nQRsAAACoAII2AAAAUAEEbQAAAKACCNoAAABABTii8g8xrxbbOyU9k8Ktp0jalcJ9UV2Mc31gnGsf\nY1wfGOf6kNY4nx4RU491UE0F7bTYbo+ItrTrQGUxzvWBca59jHF9YJzrw0gfZ5aOAAAAABVA0AYA\nAAAqgKA9PK5LuwBUBeNcHxjn2scY1wfGuT6M6HFmjTYAAABQAcxoAwAAABVA0B4C25fafsr2etuf\nSbseHB9HKOHQAAAFJElEQVTbX7W9w/a6sr6Tbd9l++nkfXLZvr9Oxvop2/+hrP9c248m+75g29X+\nWTAw27Nt/8L247Yfs/3ppJ+xrhG2W2zfb/vhZIz/NulnjGuQ7azt39r+YbLNONcY25uT8XnIdnvS\nNyrHmaB9gmxnJX1R0jsknSnpCttnplsVjtNNki7t0/cZSXdHxAJJdyfbSsb2cklnJed8KfnfgCSt\nkPRJSQuSV99rIl15SX8eEWdKOk/Sp5LxZKxrR5ekN0fEOZIWSrrU9nlijGvVpyU9UbbNONemSyJi\nYdmj+0blOBO0T9wiSesjYmNEdEu6VdJ7Uq4JxyEi7pG0u0/3eyTdnLRvlvTesv5bI6IrIjZJWi9p\nke3pkiZGxH1R+oOHr5WdgxEgIrZHxINJe59K/4GeKca6ZkTJ/mSzMXmFGOOaY3uWpHdJuqGsm3Gu\nD6NynAnaJ26mpGfLtrcmfRjdpkXE9qT9vKRpSXug8Z6ZtPv2YwSyPVfS6yT9Rox1TUmWEzwkaYek\nuyKCMa5Nn5f0l5KKZX2Mc+0JST+zvdb20qRvVI5zQ7VvCIwWERG2eSxPjbA9XtJ3JP1pROwtX6rH\nWI9+EVGQtND2SZJut/2aPvsZ41HO9rsl7YiItbaX9HcM41wzLoyIbbZPlXSX7SfLd46mcWZG+8Rt\nkzS7bHtW0ofR7YXk101K3nck/QON97ak3bcfI4jtRpVC9jcj4rtJN2NdgyJij6RfqLQWkzGuLW+S\ndJntzSot13yz7W+Ica45EbEted8h6XaVluuOynEmaJ+4ByQtsD3PdpNKC/HvSLkmDN0dkj6etD8u\n6ftl/ZfbbrY9T6U/qrg/+TXWXtvnJX/N/LGyczACJOPyFUlPRMTnynYx1jXC9tRkJlu2x0h6m6Qn\nxRjXlIj464iYFRFzVfpv7s8j4iNinGuK7XG2J/S0Jb1d0jqN0nFm6cgJioi87T+S9BNJWUlfjYjH\nUi4Lx8H2LZKWSJpie6uk/yHp7yXdZvtqSc9I+n1JiojHbN8m6XGVnmLxqeRX1ZL0hyo9wWSMpB8l\nL4wcb5L0UUmPJmt4JelvxFjXkumSbk6eNJCRdFtE/ND2vWKM6wH/X64t01Ra/iWVcuq3IuLHth/Q\nKBxnvhkSAAAAqACWjgAAAAAVQNAGAAAAKoCgDQAAAFQAQRsAAACoAII2AAAAUAEEbQCoAbYLth8q\ne31mGK891/a64boeANQLnqMNALXhYEQsTLsIAMBhzGgDQA2zvdn2P9p+1Pb9ts9I+ufa/rntR2zf\nbXtO0j/N9u22H05eFySXytq+3vZjtn+afAMjAOAoCNoAUBvG9Fk68qGyfS9HxGslXSvp80nfv0i6\nOSLOlvRNSV9I+r8gaXVEnCPp9ZJ6vvF2gaQvRsRZkvZIen+Ffx4AGPX4ZkgAqAG290fE+H76N0t6\nc0RstN0o6fmIOMX2LknTIyKX9G+PiCm2d0qaFRFdZdeYK+muiFiQbP+VpMaI+F+V/8kAYPRiRhsA\nal8M0D4eXWXtgvgbHwA4JoI2ANS+D5W935u0fy3p8qT9YUlrkvbdkpZLku2s7UnVKhIAag0zEgBQ\nG8bYfqhs+8cR0fOIv8m2H1FpVvqKpO+PJd1o+y8k7ZT0iaT/05Kus321SjPXyyVtr3j1AFCDWKMN\nADUsWaPdFhG70q4FAOoNS0cAAACACmBGGwAAAKgAZrQBAACACiBoAwAAABVA0AYAAAAqgKANAAAA\nVABBGwAAAKgAgjYAAABQAf8fxZEK5W/0PdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19222cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (12,3))\n",
    "plt.plot(step_list, loss_list, '-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal se usan 4 neuronas para el input, con 2 capas ocultas con 32 y 16 neuronas para la primera y segunda respectivamente, ambas con activación relu. La capa del output tiene una activación softmax con 3 salidas. Para abordar el problema de backpropagation se usa una función de perdida de cross entropy.\n",
    "\n",
    "Como se puede apreciar en el grafico más arriba la red neuronal al ser entrenada, disminuye el valor para la función de perdida, es decir, se entrena de buena forma. Se puede ver que en un principio se consigue una gran disminución para luego ser más pausada, las primeras veces que se entrenó bastó para darle una buena forma a la red y que está pueda predecir de buena forma casos futuros, pero se puede apreciar que hasta el último momento logró disminuir la loss function, es decir, se entrenó hasta el último ciclo como ya se dijo. Se debe tener cuidado con sobre entrenar la red, ya que se producirá overfitting y se perderá la capacidad para que la red pueda predecir de buena manera casos futuros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
